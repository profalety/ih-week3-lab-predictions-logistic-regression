{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ee9501-6e5d-4821-8c1d-408d1eb1a90a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "207d6ef7-3a13-48d7-9fd5-31a3c4816b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import getpass  # To get the password without showing the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b19855-3418-40c8-b6e6-a3261c98743c",
   "metadata": {},
   "source": [
    "# DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1ed44090-79cd-4641-8536-efc67c97f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = 'xPehv7cYgijaAN7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bcf571d8-c1a8-4f0a-a587-2ccf7b87350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/sakila'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746c047-0c7c-45d5-9e5e-ec379068e6be",
   "metadata": {},
   "source": [
    "# DB QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d4d054eb-50c2-4c21-a750-bec5c79140e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get movies\n",
    "query = 'SELECT title, rental_duration, rental_rate, length, replacement_cost, rating, count(title) as rented FROM film \\\n",
    "LEFT JOIN inventory i USING(film_id) \\\n",
    "LEFT JOIN rental r USING(inventory_id) \\\n",
    "GROUP BY title'\n",
    "df  = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75bf0bbc-ed23-4c3c-8c73-f78b6e057689",
   "metadata": {},
   "source": [
    "# get movies\n",
    "query = 'SELECT title, rental_duration, rental_rate, length, rating FROM film'\n",
    "df  = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f447583d-b3c9-45f2-a218-83be2cb079b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rentals\n",
    "query = 'SELECT title, month(rental_date) as month \\\n",
    "FROM film \\\n",
    "LEFT JOIN inventory i USING(film_id) \\\n",
    "LEFT JOIN rental r USING(inventory_id)' \n",
    "rental  = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "de7c7760-b136-493e-9b7b-51ea9803c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce ~16.000 rentals to the 1000 unique movies and set 1 for month when \n",
    "rental['month'] = np.where(rental['month']==5,1,0)\n",
    "rental = rental.groupby(['title'])['month'].max()\n",
    "rental = pd.DataFrame(rental).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aae4f49f-929e-4509-a7ef-1dbb863d75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both tables\n",
    "#df = df.join(rental.set_index('title'), on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e475b050-7476-42fc-9cb6-12e7a183d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "rental_duration     0\n",
       "rental_rate         0\n",
       "length              0\n",
       "replacement_cost    0\n",
       "rating              0\n",
       "rented              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d9e94-89fb-4889-afe4-f806b57ac056",
   "metadata": {},
   "source": [
    "# x-y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d2de9551-3b7e-4ca3-9231-f97aa0961464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to X-y-split AND train-test-split BEFORE I apply transformations, \n",
    "# then train transformation on training set only\n",
    "#y = df['month']\n",
    "#X = df.drop('month', axis=1)\n",
    "y = rental['month']\n",
    "X = df\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107bc30-a240-43cb-bca0-a3fc14aea570",
   "metadata": {},
   "source": [
    "## X_train_num scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "36b75177-a597-4f71-b416-d96af5a0586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_train_num) # need to keep transformer\n",
    "X_train_normalized = transformer.transform(X_train_num)\n",
    "X_train_norm = pd.DataFrame(X_train_normalized)\n",
    "X_train_norm.columns = X_train_num.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc9a03-baa5-459c-8e7b-352f6916d150",
   "metadata": {
    "tags": []
   },
   "source": [
    "## X_train_cat Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eb3d14d8-3c46-49e8-aa8a-76c00766c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes(include = object)\n",
    "X_train_cat = X_train_cat.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2b1f5beb-e2ce-4b4f-8035-48dedf94e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder().fit(X_train_cat)\n",
    "encoded = encoder.transform(X_train_cat).toarray()\n",
    "cols=[colname for row in encoder.categories_ for colname in row]\n",
    "onehot_encoded = pd.DataFrame(encoded,columns=cols)\n",
    "cols_to_drop=[row[0] for row in encoder.categories_]\n",
    "X_train_cat = onehot_encoded.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a24f5aa0-9428-48de-8101-0c810623e044",
   "metadata": {},
   "source": [
    "X_train_cat = pd.get_dummies(X_train_cat, \n",
    "                             columns=['rating'],\n",
    "                             drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56795660-ad18-471e-a634-01dd088bcbcb",
   "metadata": {},
   "source": [
    "## LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5519b3c2-fdc7-4808-b865-7e8256f8d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = np.concatenate([X_train_norm, X_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "289ba781-75c8-452e-9025-5c74a86194e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='saga', # lbfgs - saga\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf48b8c-0f85-4106-8d8e-23b3231b1983",
   "metadata": {},
   "source": [
    "## X_test_num scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d3479896-1ef0-45b1-80de-2067a9e69efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numericals\n",
    "X_test_num = X_test.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "# we use the transformer that was trained on the training data\n",
    "X_test_normalized = transformer.transform(X_test_num)\n",
    "X_test_norm = pd.DataFrame(X_test_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f826a9c-b700-4e5f-aaf2-2071b58b1e4b",
   "metadata": {},
   "source": [
    "## X_test_cat Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3b9e719e-2b0c-465d-b895-11e9597b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat = X_test.select_dtypes(include = object)\n",
    "X_test_cat = X_test_cat.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9821030d-4b0e-48ab-b3fa-b384c517bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder().fit(X_test_cat)\n",
    "encoded = encoder.transform(X_test_cat).toarray()\n",
    "cols=[colname for row in encoder.categories_ for colname in row]\n",
    "onehot_encoded = pd.DataFrame(encoded,columns=cols)\n",
    "cols_to_drop=[row[0] for row in encoder.categories_]\n",
    "X_test_cat = onehot_encoded.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3390e89-6bbe-4ec7-ba63-74a4c8499cf2",
   "metadata": {},
   "source": [
    "# for categoricals\n",
    "X_test_cat = pd.get_dummies(X_test_cat, \n",
    "                            columns=['rating'],\n",
    "                            drop_first=True)\n",
    "# verify that dummies columns are in the same order and that the same column was dropped\n",
    "display(list(zip(list(X_train_cat.columns),list(X_test_cat.columns))))\n",
    "# not needed if you treat each dataframe with one_hot_encoder and save the encode (and the column names)\n",
    "\n",
    "X_test_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61349ac-5bae-4beb-abf4-f990f95e49e4",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "30c38594-d4a7-4164-8689-820f3051ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = np.concatenate([X_test_norm, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bc5de5a1-5812-4129-a25a-a252fdec1d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classification.predict(X_test_transformed)\n",
    "classification.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e68a9c3f-0efa-4eb3-a31e-96cf57183fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e0e07-91e0-46cf-a9a1-53bf49527978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
